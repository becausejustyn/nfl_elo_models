{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import jit, grad, tree_multimap\n",
    "import optax\n",
    "from jax_util import optimise, get_target, get_log_loss, predict_proba, update_ratings, scan_dataset, negative_average_log_loss, EloRatingNet\n",
    "\n",
    "__EPS__ = 1e-12\n",
    "learning_rate = 0.01\n",
    "n_gradient_steps = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "teamA_rating = 2.1\n",
    "teamB_rating = 1.1\n",
    "allow_draw = True\n",
    "params = {\"gamma\": 0.1, \"beta\": 1, \"alpha\": 0}\n",
    "scores = (3, 1)\n",
    "\n",
    "y = get_target(scores)\n",
    "probabilities = predict_proba(params, teamA_rating, teamB_rating, allow_draw)\n",
    "\n",
    "print(f\"The probability of team A to win is {probabilities[0].round(2)*100}%, team B to win is {probabilities[2].round(2)*100}%, and the draw is {probabilities[1].round(2)*100}%\")\n",
    "print(f\"Team A wins the game, the log loss is {get_log_loss(y,probabilities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "rating = jnp.array([100, 100], dtype=float)\n",
    "teamA_idx = 0\n",
    "teamB_idx = 1\n",
    "\n",
    "params = {\"gamma\": 0.1, \"beta\": 1, \"alpha\": 0}\n",
    "params[\"kappa\"] = 1\n",
    "\n",
    "y = 1\n",
    "teamA_idx = 0\n",
    "teamB_idx = 1\n",
    "allow_draw = True\n",
    "\n",
    "new_rating = update_ratings(params, teamA_idx, teamB_idx, y, rating, allow_draw)\n",
    "print(f\"Rating was {rating}, the new rating is {new_rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "\n",
    "# init the model\n",
    "elo_model = EloRatingNet(n_teams=2)\n",
    "params = elo_model.init_params()\n",
    "\n",
    "# create toy dataset with 2 teams and 2 matches. \n",
    "# first, team A (index 0) plays team B (index 1) and won 3-1.\n",
    "# second, team B plays team A and it is a draw.\n",
    "toy_dataset = {\n",
    "    \"team_index\": jnp.array([[0, 1], [1, 0]]),\n",
    "    \"scores\": jnp.array([[3.0, 1.0], [1.0, 1.0]]),\n",
    "}\n",
    "\n",
    "output = scan_dataset(params, toy_dataset)\n",
    "print(f\"The log-loss of the two matches is {output['loss_history']}\")\n",
    "\n",
    "loss = negative_average_log_loss(params, toy_dataset)\n",
    "print(f\"The dataset negative log loss is {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jax magic gradient\n",
    "negative_average_log_loss_grad_fn = jit(grad(negative_average_log_loss))\n",
    "\n",
    "grads = negative_average_log_loss_grad_fn(params, toy_dataset)\n",
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of one gradient descent step \"handmade\"\n",
    "\n",
    "# init params\n",
    "params = elo_model.init_params()\n",
    "\n",
    "for key, val in params.items():\n",
    "    if isinstance(params[key], list):\n",
    "        # update r0 list parameters\n",
    "        params[key] = jnp.array([v - learning_rate * grads[key][k] for k, v in enumerate(params[key])])\n",
    "    else:\n",
    "        # update float parameters\n",
    "        params[key] = val - learning_rate * grads[key]\n",
    "print(\"Parameters after the handmade gradient step:\")\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of one gradient descent step with tree_multimap\n",
    "\n",
    "# init params\n",
    "params = elo_model.init_params()\n",
    "params = tree_multimap(lambda p, g: p - learning_rate * g, params, grads)\n",
    "print(\"Parameters after the tree_multimap gradient step:\")\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of one gradient descent step with optax\n",
    "\n",
    "# init params\n",
    "params = elo_model.init_params()\n",
    "# 1. pick an optimisor method: we use classical sgd as previously\n",
    "tx = optax.sgd(learning_rate=learning_rate)\n",
    "# 2. init the optimisor state\n",
    "opt_state = tx.init(params)\n",
    "# 3. update: this step returns the updates pytree of the parameters and the new opt_state.\n",
    "updates, opt_state = tx.update(grads, opt_state)\n",
    "# 4. update the parameters. This step is equivalent to jax.tree_map(lambda x,y: x+y, params, updates)\n",
    "params = optax.apply_updates(params, updates)\n",
    "print(\"Parameters after the Optax gradient step:\")\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: 500 gradient steps  on our toy_dataset\n",
    "\n",
    "elo_model = EloRatingNet(n_teams=2)\n",
    "optimiser = optax.sgd(learning_rate=0.01)\n",
    "\n",
    "params = elo_model.init_params()\n",
    "params = optimise(params, optimiser, toy_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from jax_util import EloDataset\n",
    "\n",
    "# load the data\n",
    "data = (\n",
    "    pd.read_csv(\"../input/barclays-premier-league/match.csv\")\n",
    "    .sort_values(\"match_date\")\n",
    "    .iloc[1:]\n",
    ")\n",
    "\n",
    "# map team's index into names\n",
    "clubs = pd.read_csv(\"../input/barclays-premier-league/club.csv\")\n",
    "clubs.index = clubs.club_id\n",
    "data[\"home_team_name\"] = clubs.loc[data[\"home_team_id\"], \"club_name\"].values\n",
    "data[\"away_team_name\"] = clubs.loc[data[\"away_team_id\"], \"club_name\"].values\n",
    "\n",
    "# init the EloDataset. Note taht we also pass the time index.\n",
    "football_data = EloDataset(\n",
    "    valid_date=\"2014-06-01\", # validation set starts here, train is all dates before\n",
    "    test_date=\"2018-06-01\", # test set starts here\n",
    "    time=pd.DatetimeIndex(data[\"match_date\"]),\n",
    ")\n",
    "\n",
    "# prepare the data\n",
    "football_data.prepare_data(\n",
    "    data[[\"home_team_name\", \"away_team_name\"]],\n",
    "    data[[\"home_team_goals\", \"away_team_goals\"]],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the class. Draw is possible in football.\n",
    "model = EloRatingNet(allow_draw=True)\n",
    "\n",
    "# chain/customise the optimiser\n",
    "optimiser = optax.chain(\n",
    "    optax.sgd(learning_rate=0.05), # we use sgd\n",
    "    optax.keep_params_nonnegative() # we constrain the parameters\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "model.fit_parameters(\n",
    "    football_data, optimiser, max_step=1000, early_stopping=100, verbose=50\n",
    ")\n",
    "\n",
    "model.ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_rating_history(['Liverpool','Manchester City'])\n",
    "model.predict_proba('Liverpool','Manchester City')\n",
    "\n",
    "# sgdr_schedule: schedule multiple warmup_cosine_decay_schedule using a list of dict of parameters.\n",
    "n_schedules = 10\n",
    "schedule = optax.sgdr_schedule(\n",
    "    [\n",
    "        dict(\n",
    "            init_value=0.05 / ((i + 1)), # initial value of the lr\n",
    "            peak_value=0.3 / (i + 1),# peak value of the lr\n",
    "            warmup_steps=30,# step value of the peak_value\n",
    "            decay_steps=100,# step value of the end_value\n",
    "            end_value=0.05 / ((i + 1) + 1),# end value of the lr\n",
    "        )\n",
    "        for i in range(1, n_schedules)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# plot\n",
    "n_gradient_steps = 1000\n",
    "_ = (\n",
    "    pd.Series([schedule(i) for i in range(n_gradient_steps)])\n",
    "    .astype(float)\n",
    "    .plot(\n",
    "        title=\"Chained warmup cosine decay schedule\",\n",
    "        xlabel=\"gradient step\",\n",
    "        ylabel=\"learnin rate\",\n",
    "        figsize=(11, 7),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
